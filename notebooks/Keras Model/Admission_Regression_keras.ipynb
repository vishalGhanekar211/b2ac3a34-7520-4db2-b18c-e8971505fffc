{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ad35b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense ,Dropout,BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003ef58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>TOEFL</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Admission_Chance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>330</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>308</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>302</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>323</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE  TOEFL  University Rating  SOP  LOR   CGPA  Research  Admission_Chance\n",
       "0  337    118                  4  4.5   4.5  9.65         1              0.92\n",
       "1  324    107                  4  4.0   4.5  8.87         1              0.76\n",
       "2  316    104                  3  3.0   3.5  8.00         1              0.72\n",
       "3  322    110                  3  3.5   2.5  8.67         1              0.80\n",
       "4  314    103                  2  2.0   3.0  8.21         0              0.65\n",
       "5  330    115                  5  4.5   3.0  9.34         1              0.90\n",
       "6  321    109                  3  3.0   4.0  8.20         1              0.75\n",
       "7  308    101                  2  3.0   4.0  7.90         0              0.68\n",
       "8  302    102                  1  2.0   1.5  8.00         0              0.50\n",
       "9  323    108                  3  3.5   3.0  8.60         0              0.45"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"/data/Admission_data.csv\")\n",
    "#changing names because previous names are little bit confusing\n",
    "df=df.rename(index=str, columns={\"GRE Score\": \"GRE\", \"TOEFL Score\": \"TOEFL\", \"Chance of Admit \": \"Admission_Chance\"})\n",
    "#we donot need serial number so its good to drop it because its just a number\n",
    "df=df.drop(\"Serial No.\",axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cfbf930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admit=np.asarray(df[\"Admission_Chance\"])\n",
    "len(np.unique(admit))\n",
    "#we have 60 different values in the coloum [chance to predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(df.drop(\"Admission_Chance\",axis=1))\n",
    "Y=np.asarray(df[\"Admission_Chance\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X,Y, test_size=0.2, random_state=0)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler =  MinMaxScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "68976208",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 16)                128       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 273\n",
      "Trainable params: 273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keras = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(16, input_dim=7, activation='relu'),\n",
    "        tf.keras.layers.Dense(8, input_dim=7, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)  \n",
    "    ]\n",
    ")\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c12bb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_keras.compile(\n",
    "    optimizer='adam',\n",
    "    #loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    loss=tf.keras.losses.MeanAbsolutePercentageError(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e232ab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 7.4653 - accuracy: 0.0000e+00 - val_loss: 7.3552 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.2364 - accuracy: 0.0000e+00 - val_loss: 7.1330 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.2656 - accuracy: 0.0000e+00 - val_loss: 7.9301 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.2623 - accuracy: 0.0000e+00 - val_loss: 7.8955 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.4937 - accuracy: 0.0000e+00 - val_loss: 7.2166 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.1951 - accuracy: 0.0000e+00 - val_loss: 7.1329 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.8908 - accuracy: 0.0000e+00 - val_loss: 7.8502 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.3068 - accuracy: 0.0000e+00 - val_loss: 7.0173 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.1253 - accuracy: 0.0000e+00 - val_loss: 8.5613 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.1319 - accuracy: 0.0000e+00 - val_loss: 7.1798 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.7975 - accuracy: 0.0000e+00 - val_loss: 7.1488 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.8641 - accuracy: 0.0000e+00 - val_loss: 6.8944 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.8505 - accuracy: 0.0000e+00 - val_loss: 7.0438 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.7570 - accuracy: 0.0000e+00 - val_loss: 7.0534 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.0416 - accuracy: 0.0000e+00 - val_loss: 7.0556 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.8097 - accuracy: 0.0000e+00 - val_loss: 7.2621 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f309c150940>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model_keras.fit(X_train, y_train, batch_size=5, epochs=20, validation_split=0.2,\n",
    "          callbacks=[EarlyStopping(monitor='val_loss', patience=4)])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "298f1ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 12.6108 - accuracy: 0.0000e+00\n",
      "Test loss:  12.610831260681152\n",
      "Test accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "test_scores = model_keras.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_scores[0])\n",
    "print(\"Test accuracy: \", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d58b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "'''\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Dense(16, input_dim=7, activation='relu'))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(8, input_dim=7, activation='relu'))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96c10b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimator = KerasRegressor(build_fn=baseline_model, epochs=30, batch_size=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "caa367c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f30a57e9510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f30a57e9510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f30a57e9510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "134/134 [==============================] - 0s 678us/step - loss: 0.0585\n",
      "Epoch 2/30\n",
      "134/134 [==============================] - 0s 643us/step - loss: 0.0081\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 0s 646us/step - loss: 0.0051\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 0s 672us/step - loss: 0.0056\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 0s 680us/step - loss: 0.0048\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 0s 654us/step - loss: 0.0037\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 0s 667us/step - loss: 0.0036\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 0s 631us/step - loss: 0.0041\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 0s 668us/step - loss: 0.0041\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 0s 650us/step - loss: 0.0032\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 0s 640us/step - loss: 0.0049\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 0s 641us/step - loss: 0.0040\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 0s 692us/step - loss: 0.0035\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 0s 740us/step - loss: 0.0037\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 0s 687us/step - loss: 0.0036\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 0s 682us/step - loss: 0.0038\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 0s 651us/step - loss: 0.0040\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 0s 674us/step - loss: 0.0037\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 0s 670us/step - loss: 0.0031\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 0s 639us/step - loss: 0.0038\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 0s 688us/step - loss: 0.0037\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 0s 671us/step - loss: 0.0033\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 0s 673us/step - loss: 0.0040\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 0s 652us/step - loss: 0.0033\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 0s 630us/step - loss: 0.0027\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 0s 652us/step - loss: 0.0035\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 0s 667us/step - loss: 0.0040\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 0s 671us/step - loss: 0.0032\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 0s 695us/step - loss: 0.0039\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 0s 656us/step - loss: 0.0031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f312838e550>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2034ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f30a58e7840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f30a58e7840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f30a58e7840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#prediction = model_kr.predict(X_test)\n",
    "#prediction = model_keras.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed41e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error =  np.abs(y_test - prediction)\n",
    "mean_error = np.mean(train_error)\n",
    "min_error = np.min(train_error)\n",
    "max_error = np.max(train_error)\n",
    "std_error = np.std(train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b2d8935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_error:  0.2183339889187915\n",
      "mean_error:  0.9923342969641089\n",
      "min_error:  0.38266856350004674\n",
      "max_error:  1.594684920310974\n"
     ]
    }
   ],
   "source": [
    "print(\"std_error: \",std_error)\n",
    "print(\"mean_error: \",mean_error)\n",
    "print(\"min_error: \",min_error)\n",
    "print(\"max_error: \",max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "296a1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model function\n",
    "def model(algorithm,dtrain_X,dtrain_Y,dtest_X,dtest_Y,cols=None):\n",
    "\n",
    "    #algorithm.fit(dtrain_X,dtrain_Y)\n",
    "    predictions = algorithm.predict(dtest_X)\n",
    "    prediction_probabilities = algorithm.predict(dtest_X)\n",
    "    print (algorithm)\n",
    "    \n",
    "    return predictions,prediction_probabilities,algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb15d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f30a588bbf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f30a588bbf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f30a588bbf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3128376da0>\n"
     ]
    }
   ],
   "source": [
    "#y_pred,y_prob,model_obj=model(estimator,X_train,y_train,X_test,y_test)\n",
    "y_pred,y_prob,model_obj=model(model_keras,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "74374218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mosaicml import *\n",
    "from mosaicml.constants import MLModelFlavours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a7b3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload = request.json[\"payload\"]\n",
    "    data = pd.DataFrame(eval(payload))\n",
    "    prediction = model.predict(data)\n",
    "    #prediction = pd.Series(model.predict(data))\n",
    "    print (prediction)\n",
    "    #return prediction\n",
    "    return prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14a2c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['GRE Score','TOEFL Score','University Rating','SOP','LOR','CGPA','Research']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94d4d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = pd.DataFrame(X,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c080707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":X_temp.head(1).to_json(orient = 'records')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c951cfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"GRE Score\":337.0,\"TOEFL Score\":118.0,\"University Rating\":4.0,\"SOP\":4.5,\"LOR\":4.5,\"CGPA\":9.65,\"Research\":1.0}]'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.json['payload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88ea61cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'payload': '[{\"GRE Score\":337.0,\"TOEFL Score\":118.0,\"University Rating\":4.0,\"SOP\":4.5,\"LOR\":4.5,\"CGPA\":9.65,\"Research\":1.0}]'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7eff8b4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "76.96239\n",
      "{'input': {'type': 'pd.core.frame.DataFrame', 'items': {'type': 'object', 'properties': {'GRE Score': {'type': 'number', 'format': 'double'}, 'TOEFL Score': {'type': 'number', 'format': 'double'}, 'University Rating': {'type': 'number', 'format': 'double'}, 'SOP': {'type': 'number', 'format': 'double'}, 'LOR': {'type': 'number', 'format': 'double'}, 'CGPA': {'type': 'number', 'format': 'double'}, 'Research': {'type': 'number', 'format': 'double'}}}, 'example': [{'GRE Score': 337.0, 'TOEFL Score': 118.0, 'University Rating': 4.0, 'SOP': 4.5, 'LOR': 4.5, 'CGPA': 9.65, 'Research': 1.0}, {'GRE Score': 324.0, 'TOEFL Score': 107.0, 'University Rating': 4.0, 'SOP': 4.0, 'LOR': 4.5, 'CGPA': 8.87, 'Research': 1.0}]}, 'output': {'type': 'number', 'format': 'double', 'example': 76.96238708496094}}\n"
     ]
    }
   ],
   "source": [
    "#sch = generate_schema(score,(model_obj, req),X_temp)\n",
    "sch = generate_schema(score,(model_keras, req),X_temp)\n",
    "print(sch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de52e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f309c120c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f309c120c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f309c120c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpoadglf6l/ml_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpoadglf6l/ml_model/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81c8e8c09584ac4b34e704377488c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model\n"
     ]
    }
   ],
   "source": [
    "register_model(model_keras, score, name=\"Admission_RegressionKERAS\", \n",
    "                description=\"Identify chances of Admission\",\n",
    "                flavour=MLModelFlavours.keras)\n",
    "'''\n",
    "               schema=sch,\n",
    "                y_true=y_test, y_pred = y_pred, #y_pred=pd.Series(y_pred), \n",
    "                prob=y_pred, features=cols, \n",
    "               labels=[\"Admission_Chance\"], \n",
    "               init_script=\"\" ,\n",
    "                model_type=\"regression\", \n",
    "                input_type=\"json\", explain_ai=True, x_train=X_train, x_test=X_test, \n",
    "                y_train=y_train, y_test=y_test,\n",
    "                feature_names=cols,feature_ids=cols,\n",
    "                target_names=[\"Admission_Chance\"], \n",
    "                kyd=False, kyd_score =False)\n",
    "'''\n",
    "print(\"Registering model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ab6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
